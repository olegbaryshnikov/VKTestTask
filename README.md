# VKTestTask
Векторные представления текста могут использоваться в задачах ранжирования, поиска документов, классификации, кластеризации и являться представлением всего документа для других задач.

## Гипотезы:
1. Большинство эмбеддингов текстов (без агрегирования) будут иметь достаточно высокие значения метрик в задаче ранжирования, т.к. в основном применяются именно для этой задачи. Для задачи ранжирования метрики эмбеддингов будут расположены в следующем порядке: GLoVe<Bert<SentenceTransformer, т.к. первые два агрегированы по токенам и для ранжирования обычно не используются.
2. Агрегированные эмбеддинги токенов будут показывать схожие результаты с эмбеддингами текстов на метриках связанных с задачами классификации и регрессии, т.к. по хорошо обученным эмбеддигам токенов обычно можно обучить модель, которая будет хорошо решать данные задачи.

## Данные эксперимента
### Метрики:
* Для оценки ранжирования воспользуемся метриками MAP и  NDCG реализованными в бенчмарке MTEB.
* Для оценки классификации воспользуемся метриками Accuracy и F1-мерой на бенчмарке MTEB

### Датасеты:
* Для задачи ранжирования выберем ["QuoraRetrieval", "SciFact", "Touche2020"]
* Для задачи классификации выберем ["EmotionClassification", "CBD", "ImdbClassification"]

### Модели:
* Из моделей основанных на Count-Based методах выберем усредненные эмбеддинги токенов GLoVe (average_word_embeddings_glove.6B.300d из SentenceTransformers)
* Выберем усредненные эмбеддинги токенов BERT (bert-base-nli-stsb-mean-tokens из SentenceTransformers)
* Выберем эмбеддинги текстов из SentenceTransformers (all-mpnet-base-v2)

## Результаты
В данном эксперименте был получен следующий результат:  
![Imgur](https://i.imgur.com/NO8YmCh.png)

1. Первая гипотеза полностью подтвердилась, метрики моделей на датасетах расположены в следующем порядке: GLoVe<Bert<SentenceTransformer.  
2. Вторую гипотезу также можем считать подтвержденной, т.к. метрики на классификации у BERT и SentenceTransformers очень близки по значению, а метрики классификации GLoVe незначительно ниже этого значения (более слабая модель).  

Метрики каждого из эмбеддингов на датасетах имеют следующий порядок QuoraRetrieval>SciFact>Touche2020 на задаче ранжирования и ImdbClassification>CBD>EmotionClassification на задаче классификации. Это говорит нам скорее о сложности выполнения поставленной задачи на каждом из датасетов, чем о качестве эмбеддингов.
